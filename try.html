<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AI Sign Language Reader — Demo</title>
  <meta name="description" content="Front-end for an AI Sign Language Reader. HTML, CSS and vanilla JS only." />
  <style>
    /* --- Basic reset & layout --- */
    :root{
      --accent:#2563eb; /* blue */
      --muted:#6b7280;
      --glass: rgba(255,255,255,0.6);
      font-family: Inter, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    }
    *{box-sizing:border-box}
    html,body{height:100%;margin:0;background:linear-gradient(180deg,#f8fafc,#eef2ff);color:#0f172a}
    header{display:flex;gap:16px;align-items:center;padding:18px;max-width:1100px;margin:0 auto}
    .brand{display:flex;gap:12px;align-items:center}
    .logo{width:46px;height:46px;border-radius:10px;background:linear-gradient(135deg,var(--accent),#4f46e5);display:grid;place-items:center;color:white;font-weight:700}
    main{max-width:1100px;margin:12px auto;padding:18px}

    /* grid for two-column app */
    .app-grid{display:grid;grid-template-columns:1fr 420px;gap:20px}
    @media (max-width:980px){.app-grid{grid-template-columns:1fr;}}

    /* left card */
    .card{background:var(--glass);backdrop-filter:blur(6px);border-radius:14px;padding:16px;box-shadow:0 6px 18px rgba(2,6,23,0.06)}
    .controls{display:flex;gap:8px;flex-wrap:wrap}
    button{background:white;border:1px solid rgba(15,23,42,0.06);padding:8px 12px;border-radius:8px;cursor:pointer}
    button.primary{background:var(--accent);color:#fff;border:none}
    button.warn{background:#ef4444;color:#fff;border:none}
    input[type=file]{display:none}

    /* video & canvas area */
    .viewer{display:flex;gap:12px;align-items:flex-start}
    video,canvas{width:100%;height:auto;border-radius:10px;background:#000}
    .preview{width:260px}

    /* results */
    .results{margin-top:12px}
    .result-item{display:flex;justify-content:space-between;align-items:center;padding:8px;border-radius:8px;background:rgba(255,255,255,0.55);margin-bottom:8px}
    .progress{height:10px;border-radius:999px;background:#e6edf9;flex:1;margin-left:12px;overflow:hidden}
    .progress > span{display:block;height:100%;width:0%;background:linear-gradient(90deg,var(--accent),#7c3aed)}

    /* right column info */
    aside.card{position:sticky;top:18px;height:fit-content}
    h1{font-size:20px;margin:0}
    p.lead{color:var(--muted);margin:6px 0 12px}
    small.note{color:var(--muted)}

    footer{max-width:1100px;margin:18px auto;padding:12px;text-align:center;color:var(--muted)}

    /* accessible focus states */
    button:focus{outline:3px solid rgba(37,99,235,0.18)}

    /* tidy form */
    .row{display:flex;gap:8px;align-items:center}
    label.switch{display:inline-flex;align-items:center;gap:8px;cursor:pointer}
  </style>
</head>
<body>
  <header>
    <div class="brand">
      <div class="logo">AS</div>
      <div>
        <strong>AI Sign Reader</strong>
        <div style="font-size:13px;color:var(--muted)">Accessible demo — HTML · CSS · JavaScript</div>
      </div>
    </div>
    <nav style="margin-left:auto;color:var(--muted);font-size:14px">
      <span style="margin-right:12px">Teacher-friendly</span>
      <span>Beginner-friendly</span>
    </nav>
  </header>

  <main>
    <div class="app-grid">
      <!-- LEFT: live view + controls -->
      <section class="card" aria-labelledby="live-heading">
        <h1 id="live-heading">Live capture & prediction</h1>
        <p class="lead">Use your webcam or upload an image/video. This front-end sends frames to a backend AI endpoint — or runs a demo mode so your teacher can test it offline.</p>

        <div class="controls" role="group" aria-label="camera controls">
          <button id="startCam" class="primary">Start Camera</button>
          <button id="stopCam">Stop Camera</button>
          <button id="startPredict" class="primary">Start Prediction</button>
          <button id="stopPredict">Stop Prediction</button>
          <label class="switch" title="Enable demo predictions"><input id="demoMode" type="checkbox" aria-label="Demo mode"> Demo mode</label>
          <label for="fileUpload" style="display:inline-block"><button>Upload Image</button></label>
          <input id="fileUpload" accept="image/*" type="file">
        </div>

        <div style="height:12px"></div>
        <div class="viewer" aria-live="polite">
          <div style="flex:1">
            <video id="video" playsinline autoplay muted></video>
            <canvas id="overlay" width="640" height="480" style="display:none"></canvas>
          </div>

          <div class="preview">
            <div style="font-size:13px;color:var(--muted);margin-bottom:6px">Latest prediction</div>
            <div id="topPrediction" class="result-item">
              <div>
                <div id="predLabel" style="font-weight:700">—</div>
                <small id="predTime" class="note">No data</small>
              </div>
              <div style="width:120px">
                <div class="progress" aria-hidden="true"><span id="predBar"></span></div>
              </div>
            </div>

            <div class="results" id="detailedResults" aria-live="polite"></div>

            <div style="margin-top:8px;font-size:13px;color:var(--muted)">Backend: <strong id="backendUrl">/predict</strong></div>
          </div>
        </div>

        <details style="margin-top:12px">
          <summary>How it works (short)</summary>
          <ol>
            <li>Front-end captures a frame from the webcam (or uploaded image).</li>
            <li>It sends the image to the backend endpoint (POST /predict).</li>
            <li>Backend returns label + confidence scores. UI displays results.</li>
            <li>If <em>Demo mode</em> is toggled, the UI simulates predictions locally so the teacher can test without an AI server.</li>
          </ol>
        </details>
      </section>

      <!-- RIGHT: info, synopsis & settings -->
      <aside class="card" aria-labelledby="info-heading">
        <h2 id="info-heading">Project synopsis & settings</h2>
        <p class="lead">A minimal, honest front-end for your AI Sign Language Reader. No external libraries — easy to show to your teacher.</p>

        <div style="margin-top:8px">
          <label style="display:block;font-size:13px">Backend endpoint (change if needed)</label>
          <input id="backendInput" type="text" value="/predict" style="width:100%;padding:8px;border-radius:8px;border:1px solid #d1d5db">
        </div>

        <div style="margin-top:12px">
          <strong>What to plug in</strong>
          <ul style="padding-left:18px;color:var(--muted)">
            <li>POST /predict — FormData field named <code>image</code> (jpeg/png) OR JSON with base64.</li>
            <li>Response: <code>{ label: 'A', scores: [{label:'A',score:0.9}, ...] }</code></li>
          </ul>
        </div>

        <div style="margin-top:12px">
          <strong>Notes for teacher</strong>
          <p class="note">This page is intentionally simple: semantic HTML, good contrast, keyboard-focusable controls, and comments so a reviewer can see how the front-end works.</p>
        </div>

        <div style="margin-top:12px">
          <button id="downloadReport">Download simple report</button>
        </div>

      </aside>
    </div>
  </main>

  <footer>
    <small>Made with ❤️ — purely HTML, CSS and JavaScript. For integration details, hand this file to your backend teammate.</small>
  </footer>

  <script>
    // ----------------------
    // Simple, well-commented front-end logic
    // ----------------------

    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const startCam = document.getElementById('startCam');
    const stopCam = document.getElementById('stopCam');
    const startPredict = document.getElementById('startPredict');
    const stopPredict = document.getElementById('stopPredict');
    const fileUpload = document.getElementById('fileUpload');
    const predLabel = document.getElementById('predLabel');
    const predBar = document.getElementById('predBar');
    const predTime = document.getElementById('predTime');
    const detailedResults = document.getElementById('detailedResults');
    const backendInput = document.getElementById('backendInput');
    const backendUrlDisplay = document.getElementById('backendUrl');
    const demoModeCheckbox = document.getElementById('demoMode');
    const downloadReportBtn = document.getElementById('downloadReport');

    let stream = null;
    let predictInterval = null;
    let lastPrediction = null;

    // Basic list of demo labels (substitute with your dataset's labels)
    const DEMO_LABELS = ['A','B','C','D','E','HELLO','YES','NO','THANK YOU'];

    // Utility: update backend shown
    function updateBackendDisplay(){ backendUrlDisplay.textContent = backendInput.value.trim() || '/predict'; }
    backendInput.addEventListener('change', updateBackendDisplay);
    updateBackendDisplay();

    // Start camera (asks permission)
    startCam.addEventListener('click', async ()=>{
      try{
        stream = await navigator.mediaDevices.getUserMedia({video:{width:640,height:480},audio:false});
        video.srcObject = stream;
        await video.play();
        // set canvas size to match video
        overlay.width = video.videoWidth || 640;
        overlay.height = video.videoHeight || 480;
      }catch(err){
        alert('Could not access camera: '+err.message + '\nTip: use a secure (https) origin or localhost.');
      }
    });

    stopCam.addEventListener('click', ()=>{
      if(stream){
        stream.getTracks().forEach(t=>t.stop());
        stream = null;
        video.pause();
        video.srcObject = null;
      }
    });

    // Take snapshot from video into a blob (jpeg)
    async function captureFrameAsBlob(){
      const w = overlay.width;
      const h = overlay.height;
      ctx.drawImage(video,0,0,w,h);
      return new Promise(resolve=>{
        overlay.toBlob(blob=>resolve(blob),'image/jpeg',0.85);
      });
    }

    // Send image to backend
    async function sendToBackend(blob){
      const url = backendInput.value.trim() || '/predict';
      // two common patterns shown in comments: FormData or base64 JSON
      // 1) FormData (recommended): field name "image"
      const fd = new FormData();
      fd.append('image', blob, 'frame.jpg');
      try{
        const res = await fetch(url, {method:'POST', body:fd});
        if(!res.ok) throw new Error('Server returned '+res.status);
        const data = await res.json();
        return data;
      }catch(err){
        console.warn('Backend request failed:', err);
        return null;
      }
    }

    // Demo mode: produce a fake prediction so the UI can be shown without a working backend
    function produceDemoPrediction(){
      // random label + softmax-like distribution
      const label = DEMO_LABELS[Math.floor(Math.random()*DEMO_LABELS.length)];
      const topScore = (Math.random()*0.4)+0.5; // 0.5 - 0.9
      const others = DEMO_LABELS.filter(l=>l!==label).slice(0,4).map(l=>({label:l,score:Math.random()*0.4}));
      const scores = [{label,label,score:topScore}, ...others].slice(0,5);
      return {label, scores};
    }

    // Render prediction to UI
    function renderPrediction(resp){
      if(!resp){
        predLabel.textContent = 'No response';
        predTime.textContent = new Date().toLocaleTimeString();
        predBar.style.width = '0%';
        detailedResults.innerHTML = '';
        return;
      }
      const label = resp.label || (resp.scores && resp.scores[0] && resp.scores[0].label) || '—';
      const topScore = (resp.scores && resp.scores[0] && resp.scores[0].score) || (resp.score) || 0;
      predLabel.textContent = label;
      predTime.textContent = new Date().toLocaleTimeString();
      predBar.style.width = Math.round((topScore||0)*100)+'%';

      // detailed list
      detailedResults.innerHTML = '';
      const scores = Array.isArray(resp.scores) ? resp.scores : [];
      scores.slice(0,6).forEach(s=>{
        const div = document.createElement('div');
        div.className = 'result-item';
        div.innerHTML = `<div><strong>${s.label}</strong><div style='font-size:12px;color:var(--muted)'>score ${Math.round(s.score*100)}%</div></div><div style='width:120px'><div class='progress' aria-hidden='true'><span style='width:${Math.round(s.score*100)}%'></span></div></div>`;
        detailedResults.appendChild(div);
      });
    }

    // Periodic prediction loop
    startPredict.addEventListener('click', ()=>{
      if(predictInterval) return; // already running
      if(!stream && !demoModeCheckbox.checked){
        alert('Start the camera first, or enable Demo mode to test without a webcam.');
        return;
      }
      predictInterval = setInterval(async ()=>{
        // take a snapshot
        let resp = null;
        if(demoModeCheckbox.checked){
          resp = produceDemoPrediction();
        }else{
          const blob = await captureFrameAsBlob();
          resp = await sendToBackend(blob);
          // fallback to demo if backend failed
          if(!resp){ resp = produceDemoPrediction(); }
        }
        lastPrediction = resp;
        renderPrediction(resp);
      }, 900); // send roughly 1 frame per second (keeps resource use reasonable)
    });

    stopPredict.addEventListener('click', ()=>{
      if(predictInterval){ clearInterval(predictInterval); predictInterval = null; }
    });

    // Handle uploaded image for single prediction
    fileUpload.addEventListener('change', async (e)=>{
      const f = e.target.files[0];
      if(!f) return;
      // show uploaded image in canvas
      const img = new Image();
      img.onload = ()=>{
        overlay.width = img.width; overlay.height = img.height; ctx.drawImage(img,0,0);
      };
      img.src = URL.createObjectURL(f);

      // send to backend or demo
      if(demoModeCheckbox.checked){ renderPrediction(produceDemoPrediction()); }
      else{
        const resp = await sendToBackend(f);
        if(!resp) renderPrediction(produceDemoPrediction()); else renderPrediction(resp);
      }
    });

    // Download a tiny text report (for teacher demo)
    downloadReportBtn.addEventListener('click', ()=>{
      const txt = `AI Sign Reader - quick report\nTime: ${new Date().toLocaleString()}\nBackend: ${backendInput.value}\nLast prediction: ${JSON.stringify(lastPrediction, null, 2)}`;
      const blob = new Blob([txt],{type:'text/plain'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a'); a.href = url; a.download = 'ai-sign-reader-report.txt'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
    });

    // Accessibility: keyboard shortcuts
    window.addEventListener('keydown', (e)=>{
      if(e.key==='1') startCam.click();
      if(e.key==='2') stopCam.click();
      if(e.key==='3') startPredict.click();
      if(e.key==='4') stopPredict.click();
    });

    // Small safety note in console for reviewer
    console.log('AI Sign Reader front-end loaded. For full live camera support you must serve this page over https or from localhost.');

    // End of script
  </script>
</body>
</html>