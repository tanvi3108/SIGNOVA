# **Signova – Sign Language to Text Converter (Web + FastAPI)**

**Signova** is a web-based AI application developed to convert **ASL (American Sign Language) alphabet hand gestures** into **text**.
The system uses a clean HTML/CSS frontend and a FastAPI backend powered by a Hugging Face deep-learning model.

---

## **Features**

*  Upload ASL hand-sign images
*  Instant preview before processing
*  AI model predicts ASL alphabet letters
*  Fully functional FastAPI backend
*  Responsive and simple UI
*  Easy to extend for future upgrades

---

## **Project Structure**

```
Signova/
│── frontend/
│   ├── index.html          # Home page
│   ├── converter.html      # Upload + conversion UI
│   ├── aboutus.html        # About page
│   ├── main.html           # Extra page
│   ├── logo.png            # App logo
│   └── script.js           # Image preview + backend API request
│
│── main.py                 # FastAPI backend (prediction API)
│── requirements.txt        # Python dependencies
│── readme.md               # Documentation
│── __pycache__/            # Auto-generated by Python (ignored)
```


---

## **Model Used**

Signova uses the Hugging Face model:

**Model Name:** `prithivMLmods/Alphabet-Sign-Language-Detection`
**Task:** ASL Alphabet Image Classification

Backend loads the model like this:

```python
from transformers import pipeline

pipe = pipeline(
    "image-classification",
    model="prithivMLmods/Alphabet-Sign-Language-Detection"
)
```

Example prediction:

```python
result = pipe(image)
predicted_class = result[0]["label"]
```

---

## **Installation**

Clone and enter the project:

```bash
git clone https://github.com/yourusername/Signova.git
cd Signova
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## **Running the Backend**

Start FastAPI by running:

```bash
uvicorn main:app --reload
```

This will start the backend at:

```
http://127.0.0.1:8000
```

### Test API

Open your browser:

```
http://127.0.0.1:8000/docs
```

You can upload an image and see predictions directly.

---

## **Running the Frontend**

1. Go to the `frontend` folder
2. Open **index.html** or **converter.html**
3. (Optional but recommended) Use VS Code **Live Server** extension for smoother loading

The frontend automatically communicates with your FastAPI backend via `script.js`.

---

## **How the System Works**

1. User selects an image
2. `script.js` shows a preview
3. Clicking **Convert to Text** sends image → FastAPI
4. Model predicts the letter
5. Result is displayed in the result box

---

## **API Endpoint**

### `POST /predict`

**Request:**

* Form-data containing an image file

**Response format:**

```json
{
  "predicted_class": "A",
  "confidence": 0.9921
}
```

---

## **Tech Stack**

### **Frontend**

* HTML
* CSS
* JavaScript

### **Backend**

* Python
* FastAPI
* Uvicorn
* Hugging Face Transformers

---

## **Future Scope**

*  Word-level gesture recognition
*  Full sentence translation
*  Browser-based real-time webcam prediction
*  Multi-hand gesture support
*  Support for other sign languages (ISL, BSL, etc.)
*  Mobile-friendly version

---

## **Contributors**

* **Tanisha Gupta** – Backend Developer & AI Model Integration
* **Tanvi Haldaun** – Frontend Developer